{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intra -  Distance Comparison of Digits spoken by Speakers using Van Rossum (VR) Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from rawHD_dataset_loader_padded_spikes import rawHD_Loader\n",
    "from scipy.signal import convolve2d\n",
    "from tqdm import trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {} \n",
    "params[\"dataset_directory\"] = \"/raw-spiking-heidleberg-digits-80input/\"\n",
    "params[\"num_samples\"] = None\n",
    "params[\"verbose\"] = False\n",
    "\n",
    "x_train = np.load(\"/its/home/ts468/PhD/Intel-Neuromorphic-Research-Project/raw-spiking-heidleberg-digits-80input/training_x_spikes.npy\", allow_pickle = True)\n",
    "y_train = np.load(\"/its/home/ts468/PhD/Intel-Neuromorphic-Research-Project/raw-spiking-heidleberg-digits-80input/training_y_spikes.npy\", allow_pickle = True)\n",
    "training_details = pd.read_csv(os.getcwd() + params.get(\"dataset_directory\") + \"training_details.csv\")\n",
    "\n",
    "speakers_list = np.array(list(training_details.loc[:, \"Speaker\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "speaker = 7\n",
    "digit = 17\n",
    "index = 28\n",
    "\n",
    "a = (x_train[np.where(speakers_list == speaker)][np.where(y_train[np.where(speakers_list == speaker)] == digit)][index][\"t\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129\n"
     ]
    }
   ],
   "source": [
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exponential_kernel_2d(size_t, size_x, tau_t, tau_x):\n",
    "    t = np.linspace(-size_t/2, size_t/2, size_t + 1, dtype='int8')\n",
    "    x = np.linspace(-size_x/2, size_x/2, size_x + 1, dtype = 'int8')\n",
    "    \n",
    "    T, X = np.meshgrid(t, x, indexing='ij')\n",
    "    \n",
    "    kernel = np.exp(-np.abs(T) / tau_t) * np.exp(-np.abs(X) / tau_x)\n",
    "    \n",
    "    # 3D Surface plot\n",
    "    fig = plt.figure(figsize=(12, 5))\n",
    "    ax2 = fig.add_subplot(1, 2, 2, projection='3d')\n",
    "    ax2.plot_surface(T, X, kernel, cmap='viridis', edgecolor='none')\n",
    "    ax2.set_title(\"3D Surface Plot of Kernel\")\n",
    "\n",
    "    plt.show() \n",
    "    \n",
    "    return kernel / np.sum(kernel)  # Normalize kernel\n",
    "\n",
    "def gaussian_kernel_2d(size_t, size_x, sigma_t = 10, sigma_x = 10, display = False):\n",
    "\n",
    "    t = np.arange(-size_t // 2, size_t // 2 + 1)\n",
    "    x = np.arange(-size_x // 2, size_x // 2 + 1)\n",
    "\n",
    "    T, X = np.meshgrid(t, x, indexing='ij')\n",
    "\n",
    "    kernel = np.exp(-((T**2) / (2 * sigma_t**2) + (X**2) / (2 * sigma_x**2)))\n",
    "    kernel /= np.sum(kernel)\n",
    "\n",
    "    if display:\n",
    "        # Plot kernel\n",
    "        fig = plt.figure(figsize=(6, 5))\n",
    "        ax = fig.add_subplot(111, projection='3d')\n",
    "        ax.plot_surface(T, X, kernel, cmap='viridis', edgecolor='none')\n",
    "        ax.set_title(\"3D Surface Plot of Gaussian Kernel\")\n",
    "        \n",
    "        plt.show()\n",
    "    \n",
    "    return kernel\n",
    "\n",
    "def get_vr_distance_2d(spike_train1, \n",
    "                       spike_train2, \n",
    "                       tau_t = 40, \n",
    "                       tau_x = 5,\n",
    "                       size_t = 40,\n",
    "                       size_x = 10, \n",
    "                       last_spike_t = 1700, \n",
    "                       num_neurons = 80,\n",
    "                       display = False,\n",
    "                       second_kernel_scale = 1.0):\n",
    "    \n",
    "    time_bins = np.arange(0, last_spike_t + 1, 1)  # 1 ms bins\n",
    "    spike_matrix1 = np.zeros((len(time_bins), num_neurons))\n",
    "    spike_matrix2 = np.zeros((len(time_bins), num_neurons))\n",
    "\n",
    "    for t, x in zip(spike_train1['t'], spike_train1['x']):\n",
    "        spike_matrix1[int(t), int(x)] = 1\n",
    "    for t, x in zip(spike_train2['t'], spike_train2['x']):\n",
    "        spike_matrix2[int(t), int(x)] = 1\n",
    "    \n",
    "    #kernel = exponential_kernel_2d(size_t = size_t, size_x = size_x, tau_t=tau_t, tau_x=tau_x)\n",
    "    kernel = gaussian_kernel_2d(size_t = size_t, size_x = size_x, sigma_x = tau_x, sigma_t = tau_t, display = display)\n",
    "    \n",
    "    smoothed1 = convolve2d(spike_matrix1, kernel, mode='same', boundary='wrap')\n",
    "    smoothed2 = convolve2d(spike_matrix2, kernel * second_kernel_scale, mode='same', boundary='wrap')\n",
    "    \n",
    "    # Compute Euclidean distance between smoothed spike matrices\n",
    "    distance = np.linalg.norm(smoothed1 - smoothed2)\n",
    "    \n",
    "    return distance, smoothed1, kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate through all digits of speaker x, and get COM\n",
    "\n",
    "def get_com_for_speaker_digit(speaker, \n",
    "                              digit, \n",
    "                              x_train = x_train, \n",
    "                              y_train = y_train,\n",
    "                              x_lim = 80,\n",
    "                              t_lim = 1600):\n",
    "\n",
    "    # get COM of each digit spoken by speaker\n",
    "    t_com_across_speaker_digit, x_com_across_speaker_digit = [], []\n",
    "\n",
    "    for index in range(y_train[np.where(speakers_list == speaker)][np.where(y_train[np.where(speakers_list == speaker)] == digit)].shape[0]):\n",
    "\n",
    "        t_com = np.mean(x_train[np.where(speakers_list == speaker)][np.where(y_train[np.where(speakers_list == speaker)] == digit)][index][\"t\"])\n",
    "        x_com = np.mean(x_train[np.where(speakers_list == speaker)][np.where(y_train[np.where(speakers_list == speaker)] == digit)][index][\"x\"])\n",
    "\n",
    "        t_com_across_speaker_digit.append(t_com)\n",
    "        x_com_across_speaker_digit.append(x_com)\n",
    "        \n",
    "    #print(f\" mean COM for t : {int(np.mean(t_com_across_speaker_digit))}\")\n",
    "    #print(f\" mean COM for x : {int(np.mean(x_com_across_speaker_digit))}\")\n",
    "    \n",
    "    # shift on both x and t\n",
    "    for index in range(y_train[np.where(speakers_list == speaker)][np.where(y_train[np.where(speakers_list == speaker)] == digit)].shape[0]):\n",
    "        \n",
    "        x_train_array = x_train[np.where(speakers_list == speaker)][np.where(y_train[np.where(speakers_list == speaker)] == digit)][index]\n",
    "        \n",
    "        x_train_array[\"t\"] += int(np.mean(t_com_across_speaker_digit)) - int(t_com_across_speaker_digit[index])\n",
    "        x_train_array[\"t\"] += int(np.mean(x_com_across_speaker_digit)) - int(x_com_across_speaker_digit[index])\n",
    "        \n",
    "        x_train_array = x_train_array[x_train_array[\"x\"] >= 0]\n",
    "        x_train_array = x_train_array[x_train_array[\"x\"] < x_lim]\n",
    "        x_train_array = x_train_array[x_train_array[\"t\"] >= 0]\n",
    "        x_train_array = x_train_array[x_train_array[\"t\"] < t_lim]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate through all digits of speaker x, and get COM\n",
    "\n",
    "def normalise_dataset(x_train, \n",
    "                      y_train,\n",
    "                      x_lim = 80,\n",
    "                      t_lim = 1600):\n",
    "    \n",
    "    for speaker in np.unique(speakers_list):\n",
    "        for digit in np.unique(y_train):\n",
    "\n",
    "            # get COM of each digit spoken by speaker\n",
    "            t_com_across_speaker_digit, x_com_across_speaker_digit = [], []\n",
    "\n",
    "            for index in range(y_train[np.where(speakers_list == speaker)][np.where(y_train[np.where(speakers_list == speaker)] == digit)].shape[0]):\n",
    "\n",
    "                t_com = np.mean(x_train[np.where(speakers_list == speaker)][np.where(y_train[np.where(speakers_list == speaker)] == digit)][index][\"t\"])\n",
    "                x_com = np.mean(x_train[np.where(speakers_list == speaker)][np.where(y_train[np.where(speakers_list == speaker)] == digit)][index][\"x\"])\n",
    "\n",
    "                t_com_across_speaker_digit.append(t_com)\n",
    "                x_com_across_speaker_digit.append(x_com)\n",
    "                \n",
    "            #print(f\" mean COM for t : {int(np.mean(t_com_across_speaker_digit))}\")\n",
    "            #print(f\" mean COM for x : {int(np.mean(x_com_across_speaker_digit))}\")\n",
    "            \n",
    "            # shift on both x and t\n",
    "            for index in range(y_train[np.where(speakers_list == speaker)][np.where(y_train[np.where(speakers_list == speaker)] == digit)].shape[0]):\n",
    "                x_train_array = x_train[np.where(speakers_list == speaker)][np.where(y_train[np.where(speakers_list == speaker)] == digit)][index]\n",
    "                \n",
    "                x_train_array[\"t\"] += int(np.mean(t_com_across_speaker_digit)) - int(t_com_across_speaker_digit[index])\n",
    "                x_train_array[\"t\"] += int(np.mean(x_com_across_speaker_digit)) - int(x_com_across_speaker_digit[index])\n",
    "                \n",
    "                x_train_array = x_train_array[x_train_array[\"x\"] >= 0]\n",
    "                x_train_array = x_train_array[x_train_array[\"x\"] < x_lim]\n",
    "                x_train_array = x_train_array[x_train_array[\"t\"] >= 0]\n",
    "                x_train_array = x_train_array[x_train_array[\"t\"] < t_lim]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "speaker = 7\n",
    "digit = 17\n",
    "index = 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129\n"
     ]
    }
   ],
   "source": [
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalise all data\n",
    "for speaker in np.unique(speakers_list):\n",
    "    for digit in np.unique(y_train):\n",
    "        get_com_for_speaker_digit(speaker,\n",
    "                                digit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comparison 0 of 199\n",
      "comparison 1 of 199\n",
      "comparison 2 of 199\n",
      "comparison 3 of 199\n",
      "comparison 4 of 199\n",
      "comparison 5 of 199\n",
      "comparison 6 of 199\n",
      "comparison 7 of 199\n",
      "comparison 8 of 199\n",
      "comparison 9 of 199\n",
      "comparison 10 of 199\n",
      "comparison 11 of 199\n",
      "comparison 12 of 199\n",
      "comparison 13 of 199\n",
      "comparison 14 of 199\n",
      "comparison 15 of 199\n",
      "comparison 16 of 199\n",
      "comparison 17 of 199\n",
      "comparison 18 of 199\n",
      "comparison 19 of 199\n",
      "comparison 20 of 199\n",
      "comparison 21 of 199\n",
      "comparison 22 of 199\n",
      "comparison 23 of 199\n",
      "comparison 24 of 199\n",
      "comparison 25 of 199\n",
      "comparison 26 of 199\n",
      "comparison 27 of 199\n",
      "comparison 28 of 199\n",
      "comparison 29 of 199\n",
      "comparison 30 of 199\n",
      "comparison 31 of 199\n",
      "comparison 32 of 199\n",
      "comparison 33 of 199\n",
      "comparison 34 of 199\n",
      "comparison 35 of 199\n",
      "comparison 36 of 199\n",
      "comparison 37 of 199\n",
      "comparison 38 of 199\n",
      "comparison 39 of 199\n",
      "comparison 40 of 199\n",
      "comparison 41 of 199\n",
      "comparison 42 of 199\n",
      "comparison 43 of 199\n",
      "comparison 44 of 199\n",
      "comparison 45 of 199\n",
      "comparison 46 of 199\n",
      "comparison 47 of 199\n",
      "comparison 48 of 199\n",
      "comparison 49 of 199\n",
      "comparison 50 of 199\n",
      "comparison 51 of 199\n",
      "comparison 52 of 199\n",
      "comparison 53 of 199\n",
      "comparison 54 of 199\n",
      "comparison 55 of 199\n",
      "comparison 56 of 199\n",
      "comparison 57 of 199\n",
      "comparison 58 of 199\n",
      "comparison 59 of 199\n",
      "comparison 60 of 199\n",
      "comparison 61 of 199\n",
      "comparison 62 of 199\n",
      "comparison 63 of 199\n",
      "comparison 64 of 199\n",
      "comparison 65 of 199\n",
      "comparison 66 of 199\n",
      "comparison 67 of 199\n",
      "comparison 68 of 199\n",
      "comparison 69 of 199\n",
      "comparison 70 of 199\n",
      "comparison 71 of 199\n",
      "comparison 72 of 199\n",
      "comparison 73 of 199\n",
      "comparison 74 of 199\n",
      "comparison 75 of 199\n",
      "comparison 76 of 199\n",
      "comparison 77 of 199\n",
      "comparison 78 of 199\n",
      "comparison 79 of 199\n",
      "comparison 80 of 199\n",
      "comparison 81 of 199\n",
      "comparison 82 of 199\n",
      "comparison 83 of 199\n",
      "comparison 84 of 199\n",
      "comparison 85 of 199\n",
      "comparison 86 of 199\n",
      "comparison 87 of 199\n",
      "comparison 88 of 199\n",
      "comparison 89 of 199\n",
      "comparison 90 of 199\n",
      "comparison 91 of 199\n",
      "comparison 92 of 199\n",
      "comparison 93 of 199\n",
      "comparison 94 of 199\n",
      "comparison 95 of 199\n",
      "comparison 96 of 199\n",
      "comparison 97 of 199\n",
      "comparison 98 of 199\n",
      "comparison 99 of 199\n",
      "comparison 100 of 199\n",
      "comparison 101 of 199\n",
      "comparison 102 of 199\n",
      "comparison 103 of 199\n",
      "comparison 104 of 199\n",
      "comparison 105 of 199\n",
      "comparison 106 of 199\n",
      "comparison 107 of 199\n",
      "comparison 108 of 199\n",
      "comparison 109 of 199\n",
      "comparison 110 of 199\n",
      "comparison 111 of 199\n",
      "comparison 112 of 199\n",
      "comparison 113 of 199\n",
      "comparison 114 of 199\n",
      "comparison 115 of 199\n",
      "comparison 116 of 199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 28/34 [00:07<00:01,  3.50it/s]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 1740 is out of bounds for axis 0 with size 1701",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index_to_compare \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(y_train[np\u001b[38;5;241m.\u001b[39mwhere(speakers_list \u001b[38;5;241m==\u001b[39m speaker)][np\u001b[38;5;241m.\u001b[39mwhere(y_train[np\u001b[38;5;241m.\u001b[39mwhere(speakers_list \u001b[38;5;241m==\u001b[39m speaker)] \u001b[38;5;241m==\u001b[39m digit)]\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]):\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m index \u001b[38;5;129;01min\u001b[39;00m trange(y_train[np\u001b[38;5;241m.\u001b[39mwhere(speakers_list \u001b[38;5;241m==\u001b[39m speaker)][np\u001b[38;5;241m.\u001b[39mwhere(y_train[np\u001b[38;5;241m.\u001b[39mwhere(speakers_list \u001b[38;5;241m==\u001b[39m speaker)] \u001b[38;5;241m==\u001b[39m digit)]\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]):\n\u001b[0;32m---> 12\u001b[0m         distance, S, _ \u001b[38;5;241m=\u001b[39m \u001b[43mget_vr_distance_2d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspeakers_list\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mspeaker\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspeakers_list\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mspeaker\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdigit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspeakers_list\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mspeaker\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspeakers_list\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mspeaker\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdigit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex_to_compare\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mdisplay\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43msize_t\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m80\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m         distance_across_digits_from_speaker\u001b[38;5;241m.\u001b[39mappend(distance)\n\u001b[1;32m     19\u001b[0m intra_VR_distance_mean[speaker_index, digit] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(distance_across_digits_from_speaker)\n",
      "Cell \u001b[0;32mIn[5], line 56\u001b[0m, in \u001b[0;36mget_vr_distance_2d\u001b[0;34m(spike_train1, spike_train2, tau_t, tau_x, size_t, size_x, last_spike_t, num_neurons, display, second_kernel_scale)\u001b[0m\n\u001b[1;32m     53\u001b[0m spike_matrix2 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;28mlen\u001b[39m(time_bins), num_neurons))\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t, x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(spike_train1[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt\u001b[39m\u001b[38;5;124m'\u001b[39m], spike_train1[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m'\u001b[39m]):\n\u001b[0;32m---> 56\u001b[0m     \u001b[43mspike_matrix1\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t, x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(spike_train2[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt\u001b[39m\u001b[38;5;124m'\u001b[39m], spike_train2[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m'\u001b[39m]):\n\u001b[1;32m     58\u001b[0m     spike_matrix2[\u001b[38;5;28mint\u001b[39m(t), \u001b[38;5;28mint\u001b[39m(x)] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 1740 is out of bounds for axis 0 with size 1701"
     ]
    }
   ],
   "source": [
    "intra_VR_distance_mean = np.zeros((10, 20))\n",
    "intra_VR_distance_std = np.zeros((10, 20))\n",
    "count = 0\n",
    "\n",
    "for speaker_index, speaker in enumerate(np.unique(speakers_list)):\n",
    "    for digit in np.unique(y_train):\n",
    "        get_com_for_speaker_digit(speaker, digit)\n",
    "        if count == 117:\n",
    "            distance_across_digits_from_speaker = []\n",
    "            for index_to_compare in range(y_train[np.where(speakers_list == speaker)][np.where(y_train[np.where(speakers_list == speaker)] == digit)].shape[0]):\n",
    "                for index in trange(y_train[np.where(speakers_list == speaker)][np.where(y_train[np.where(speakers_list == speaker)] == digit)].shape[0]):\n",
    "                    distance, S, _ = get_vr_distance_2d(x_train[np.where(speakers_list == speaker)][np.where(y_train[np.where(speakers_list == speaker)] == digit)][index],\n",
    "                                                        x_train[np.where(speakers_list == speaker)][np.where(y_train[np.where(speakers_list == speaker)] == digit)][index_to_compare],\n",
    "                                                        display = False,\n",
    "                                                        size_t = 80)\n",
    "                    \n",
    "                    distance_across_digits_from_speaker.append(distance)\n",
    "\n",
    "            intra_VR_distance_mean[speaker_index, digit] = np.mean(distance_across_digits_from_speaker)\n",
    "            intra_VR_distance_std[speaker_index, digit] = np.std(distance_across_digits_from_speaker)\n",
    "            \n",
    "        print(f\"comparison {count} of 199\")\n",
    "        count += 1\n",
    "            #np.save(\"rawHD_analyse_training_data_intra_VR_distance_mean.npy\", intra_VR_distance_mean)\n",
    "            #np.save(\"rawHD_analyse_training_data_intra_VR_distance_std.npy\", intra_VR_distance_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance, S, _ = get_vr_distance_2d(x_train[np.where(speakers_list == speaker)][np.where(y_train[np.where(speakers_list == speaker)] == digit)][index],\n",
    "                                    x_train[np.where(speakers_list == speaker)][np.where(y_train[np.where(speakers_list == speaker)] == digit)][index_to_compare],\n",
    "                                    display = False,\n",
    "                                    size_t = 80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(speaker, digit, index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train[np.where(speakers_list == speaker)][np.where(y_train[np.where(speakers_list == speaker)] == digit)][index][\"t\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genn_5_1_0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
