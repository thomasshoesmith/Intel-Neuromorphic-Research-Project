{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SC Lava Inference \n",
    "\n",
    "Still experiencing over activity, investigating weight scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from lava.proc.lif.process import LIFReset\n",
    "from lava.proc.io.source import RingBuffer\n",
    "from lava.proc.dense.process import Dense\n",
    "from lava.proc.monitor.process import Monitor\n",
    "from lava.magma.core.run_conditions import RunSteps\n",
    "from lava.magma.core.run_configs import Loihi1SimCfg, Loihi2SimCfg\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import typing as ty\n",
    "\n",
    "from SC_dataset_loader import load_gsc\n",
    "\n",
    "# Import Process level primitives\n",
    "from lava.magma.core.process.process import AbstractProcess\n",
    "from lava.magma.core.process.variable import Var\n",
    "from lava.magma.core.process.ports.ports import InPort, OutPort\n",
    "\n",
    "# Import parent classes for ProcessModels\n",
    "from lava.magma.core.model.sub.model import AbstractSubProcessModel\n",
    "from lava.magma.core.model.py.model import PyLoihiProcessModel\n",
    "\n",
    "# Import ProcessModel ports, data-types\n",
    "from lava.magma.core.model.py.ports import PyInPort, PyOutPort\n",
    "from lava.magma.core.model.py.type import LavaPyType\n",
    "\n",
    "# Import execution protocol and hardware resources\n",
    "from lava.magma.core.sync.protocols.loihi_protocol import LoihiProtocol\n",
    "from lava.magma.core.resources import CPU\n",
    "\n",
    "# Import decorators\n",
    "from lava.magma.core.decorator import implements, requires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {}\n",
    "params[\"DT_MS\"] = 1.0\n",
    "params[\"TAU_MEM\"] = 20.0\n",
    "params[\"TAU_SYN\"] = 5.0\n",
    "params[\"num_samples\"] = 1\n",
    "params[\"sample_id\"] = 0     #sample used for graph generation (starting at 0, < num_samples)\n",
    "\n",
    "params[\"NUM_INPUT\"] = 80\n",
    "params[\"NUM_HIDDEN\"] = 512\n",
    "params[\"NUM_OUTPUT\"] = 35\n",
    "\n",
    "# toggle to record spikes, useful for debugging, but memory intensive\n",
    "params[\"record_network_ih_activity\"] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!! validation dataset loaded successfully !!\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 56.5 GiB for an array with shape (94824, 2000, 80) and data type float32",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# load gsc dataset\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m train_x, train_y, validation_x, validation_y, test_x, test_y \u001b[38;5;241m=\u001b[39m \u001b[43mload_gsc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/its/home/ts468/data/rawSC/rawSC_80input_updated/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                                                                        \u001b[49m\u001b[43mnum_frames\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                                                                        \u001b[49m\u001b[38;5;66;43;03m#num_samples = params[\"num_samples\"],\u001b[39;49;00m\n\u001b[1;32m      5\u001b[0m \u001b[43m                                                                        \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m                                                                        \u001b[49m\u001b[43mto_concatenate\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/its/home/ts468/PhD/Intel-Neuromorphic-Research-Project/SC_dataset_loader.py:47\u001b[0m, in \u001b[0;36mload_gsc\u001b[0;34m(dataset_directory, num_samples, to_concatenate, num_frames, shuffle)\u001b[0m\n\u001b[1;32m     44\u001b[0m test_x, test_y \u001b[38;5;241m=\u001b[39m test_x[:num_samples], test_y[:num_samples]\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m# repeat frames for current injection over (frame) time\u001b[39;00m\n\u001b[0;32m---> 47\u001b[0m train_x \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrepeat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_frames\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m validation_x \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrepeat(validation_x, num_frames, axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     49\u001b[0m test_x \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrepeat(test_x, num_frames, axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mrepeat\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m/its/home/ts468/PhD/ve/genn_5_0/lib/python3.8/site-packages/numpy/core/fromnumeric.py:479\u001b[0m, in \u001b[0;36mrepeat\u001b[0;34m(a, repeats, axis)\u001b[0m\n\u001b[1;32m    436\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_repeat_dispatcher)\n\u001b[1;32m    437\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrepeat\u001b[39m(a, repeats, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    438\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    439\u001b[0m \u001b[38;5;124;03m    Repeat elements of an array.\u001b[39;00m\n\u001b[1;32m    440\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    477\u001b[0m \n\u001b[1;32m    478\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 479\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrepeat\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrepeats\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/its/home/ts468/PhD/ve/genn_5_0/lib/python3.8/site-packages/numpy/core/fromnumeric.py:57\u001b[0m, in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 57\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbound\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;66;03m# A TypeError occurs if the object does have such a method in its\u001b[39;00m\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;66;03m# class, but its signature is not identical to that of NumPy's. This\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;66;03m# Call _wrapit from within the except clause to ensure a potential\u001b[39;00m\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;66;03m# exception has a traceback chain.\u001b[39;00m\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "\u001b[0;31mMemoryError\u001b[0m: Unable to allocate 56.5 GiB for an array with shape (94824, 2000, 80) and data type float32"
     ]
    }
   ],
   "source": [
    "# load gsc dataset\n",
    "train_x, train_y, validation_x, validation_y, test_x, test_y = load_gsc(\"/its/home/ts468/data/rawSC/rawSC_80input_updated/\",\n",
    "                                                                        num_frames = 20,\n",
    "                                                                        #num_samples = params[\"num_samples\"],\n",
    "                                                                        shuffle = False,\n",
    "                                                                        to_concatenate = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_scale = 0.015625"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "the_x = test_x\n",
    "the_y = test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform some parmeters\n",
    "tau_mem_fac = 1.0-np.exp(-params[\"DT_MS\"]/params[\"TAU_MEM\"])\n",
    "tau_syn_fac = 1.0-np.exp(-params[\"DT_MS\"]/params[\"TAU_SYN\"])\n",
    "\n",
    "# load connections\n",
    "w_i2h = np.load(\"SC_pretrained_weights/SC_Pop0_Pop1-g.npy\")\n",
    "w_i2h = w_i2h.reshape((80,512)).T\n",
    "w_i2h *= weight_scale\n",
    "#w_i2h *= tau_mem_fac\n",
    "#w_i2h /= p[\"TAU_MEM\"]\n",
    "w_h2h = np.load(\"SC_pretrained_weights/SC_Pop1_Pop1-g.npy\")\n",
    "w_h2h = w_h2h.reshape((512,512)).T\n",
    "w_h2h *= weight_scale\n",
    "#w_h2h *= tau_mem_fac\n",
    "#w_h2h /= p[\"TAU_MEM\"]\n",
    "w_h2o = np.load(\"SC_pretrained_weights/SC_Pop1_Pop2-g.npy\")\n",
    "w_h2o = w_h2o.reshape((512,35)).T\n",
    "w_h2o *= weight_scale\n",
    "#w_h2o *= tau_mem_fac\n",
    "#w_h2o /= p[\"TAU_MEM\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpikeInput(AbstractProcess):\n",
    "    def __init__(self,\n",
    "                 vth: float,\n",
    "                 images: np.ndarray,\n",
    "                 labels: np.ndarray,\n",
    "                 dt_ms: float,\n",
    "                 tau_mem: float,\n",
    "                 num_steps_per_image: ty.Optional[int] = 2000):\n",
    "        \n",
    "        super().__init__()\n",
    "        shape = (80,)\n",
    "        self.s_out = OutPort(shape=shape)  # Input spikes to the classifier\n",
    "        self.label_out = OutPort(shape=(1,))  # Ground truth labels to OutputProc\n",
    "        self.num_steps_per_image = Var(shape=(1,), init=num_steps_per_image)\n",
    "        self.ground_truth_label = Var(shape=(1,))\n",
    "        self.v = Var(shape=shape, init=0.0)\n",
    "        self.vth = Var(shape=(1,), init=vth)\n",
    "        self.images = Var(shape = images.shape, init = images) \n",
    "        self.labels = Var(shape = labels.shape, init = labels)\n",
    "        self.alpha = Var(shape = (1,), init = np.exp(-dt_ms / tau_mem))\n",
    "\n",
    "@implements(proc=SpikeInput, protocol=LoihiProtocol)\n",
    "@requires(CPU)\n",
    "class PySpikeInputModel(PyLoihiProcessModel):\n",
    "    s_out: PyOutPort = LavaPyType(PyOutPort.VEC_DENSE, bool, precision=1)\n",
    "    label_out: PyOutPort = LavaPyType(PyOutPort.VEC_DENSE, np.int32,\n",
    "                                      precision=32)\n",
    "    num_steps_per_image: int = LavaPyType(int, int, precision=32)\n",
    "    ground_truth_label: int = LavaPyType(int, int, precision=32)\n",
    "    v: np.ndarray = LavaPyType(np.ndarray, float, precision=32)\n",
    "    vth: float = LavaPyType(float, float, precision=32)\n",
    "    images: np.ndarray = LavaPyType(np.ndarray, float, precision = 32)\n",
    "    labels: np.ndarray = LavaPyType(np.ndarray, int, precision = 32)\n",
    "    alpha: float = LavaPyType(float, float, precision = 32)\n",
    "    \n",
    "    def __init__(self, proc_params):\n",
    "        super().__init__(proc_params=proc_params)\n",
    "        self.curr_img_id = 0\n",
    "\n",
    "    def post_guard(self):\n",
    "        \"\"\"Guard function for PostManagement phase.\n",
    "        \"\"\"\n",
    "        if self.time_step % self.num_steps_per_image == 0:\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def run_post_mgmt(self):\n",
    "        \"\"\"Post-Management phase: executed only when guard function above \n",
    "        returns True.\n",
    "        \"\"\"\n",
    "        self.v = np.zeros(self.v.shape)\n",
    "        self.label_out.send(np.array([self.labels[self.curr_img_id]]))\n",
    "        self.curr_img_id += 1\n",
    "\n",
    "    def run_spk(self):\n",
    "        \"\"\"Spiking phase: executed unconditionally at every time-step\n",
    "        \"\"\"\n",
    "        self.v[:] = (self.v * self.alpha) + self.images[self.time_step - 1]\n",
    "        spikes_out = self.v > self.vth\n",
    "        self.v[spikes_out] = 0  \n",
    "        self.s_out.send(spikes_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_image_start = int(the_x.shape[0] / params[\"num_samples\"] * params[\"sample_id\"])\n",
    "sample_image_end = int((the_x.shape[0] / params[\"num_samples\"] * params[\"sample_id\"]) + the_x.shape[0] / params[\"num_samples\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = SpikeInput(vth = 1.,\n",
    "                   images = the_x,\n",
    "                   labels = the_y,\n",
    "                   dt_ms = params[\"DT_MS\"],\n",
    "                   tau_mem = params[\"TAU_MEM\"],\n",
    "                   num_steps_per_image = 2000)\n",
    "\n",
    "hidden = LIFReset(shape=(512, ),                         # Number and topological layout of units in the process\n",
    "                  vth=1.,                             # Membrane threshold\n",
    "                  dv=tau_mem_fac,                              # Inverse membrane time-constant\n",
    "                  du=tau_syn_fac,                              # Inverse synaptic time-constant\n",
    "                  bias_mant=0.0,           # Bias added to the membrane voltage in every timestep\n",
    "                  name=\"hidden\",\n",
    "                  reset_interval=2000)\n",
    "\n",
    "output = LIFReset(shape=(35, ),                         # Number and topological layout of units in the process\n",
    "                  vth=1e9,                             # Membrane threshold set so it cannot spike\n",
    "                  dv=tau_mem_fac,                              # Inverse membrane time-constant\n",
    "                  du=tau_syn_fac,                              # Inverse synaptic time-constant\n",
    "                  bias_mant=0.0,           # Bias added to the membrane voltage in every timestep\n",
    "                  name=\"output\",\n",
    "                  reset_interval=2000)\n",
    "\n",
    "in_to_hid = Dense(weights= w_i2h,     # Initial value of the weights, chosen randomly\n",
    "              name='in_to_hid')\n",
    "\n",
    "hid_to_hid = Dense(weights=w_h2h,\n",
    "                   name='hid_to_hid')\n",
    "\n",
    "hid_to_out = Dense(weights=w_h2o,\n",
    "                   name= 'hid_to_out')\n",
    "\n",
    "input.s_out.connect(in_to_hid.s_in)\n",
    "in_to_hid.a_out.connect(hidden.a_in)\n",
    "hidden.s_out.connect(hid_to_hid.s_in)\n",
    "hidden.s_out.connect(hid_to_out.s_in)\n",
    "hid_to_hid.a_out.connect(hidden.a_in)\n",
    "hid_to_out.a_out.connect(output.a_in)\n",
    "\n",
    "if params[\"record_network_ih_activity\"]:\n",
    "    # monitor outputs\n",
    "    monitor_input = Monitor()\n",
    "    monitor_hidden = Monitor()\n",
    "\n",
    "    monitor_input.probe(input.s_out, the_x.shape[0])\n",
    "    monitor_hidden.probe(hidden.s_out, the_x.shape[0])\n",
    "\n",
    "monitor_output = Monitor()\n",
    "monitor_output.probe(output.v, the_x.shape[0])\n",
    "\n",
    "num_steps = int(2000/params[\"DT_MS\"])\n",
    "print(\"number of samples:\", params[\"num_samples\"])\n",
    "\n",
    "# run something\n",
    "run_condition = RunSteps(num_steps=num_steps)\n",
    "run_cfg = Loihi2SimCfg(select_tag=\"floating_pt\") # changed 1 -> 2\n",
    "\n",
    "n_sample = params.get(\"num_samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(range(params.get(\"num_samples\"))):\n",
    "    output.run(condition=run_condition, run_cfg=run_cfg)\n",
    "\n",
    "output_v = monitor_output.get_data()\n",
    "good = 0\n",
    "\n",
    "for i in range(params[\"num_samples\"]):\n",
    "    out_v = output_v[\"output\"][\"v\"][i*num_steps:(i+1)*num_steps,:]\n",
    "    sum_v = np.sum(out_v,axis=0)\n",
    "    pred = np.argmax(sum_v)\n",
    "    print(f\"Pred: {pred}, True:{train_y[i]}\")\n",
    "    if pred == train_y[i]:\n",
    "        good += 1\n",
    "\n",
    "print(f\"test accuracy: {good/n_sample*100}\")\n",
    "#output.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if params[\"record_network_ih_activity\"]:\n",
    "    # Input spike activity\n",
    "    input_spikes = monitor_input.get_data()\n",
    "\n",
    "    process = list(input_spikes.keys())[0]\n",
    "    spikes_out = list(input_spikes[process].keys())[0]\n",
    "    input_s = input_spikes[process][spikes_out]\n",
    "\n",
    "    input_single_image = input_s[sample_image_start:sample_image_end]\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "    fig.suptitle('Input Spikes (with raw input for comparison) from lava')\n",
    "\n",
    "    for i in range(params[\"NUM_INPUT\"]):\n",
    "        ax1.scatter(np.where(input_single_image[:,i] > 0)[0], \n",
    "                    np.where(input_single_image[:,i] > 0)[0].shape[0] * [i],\n",
    "                    c = '#1f77b4',\n",
    "                    s = 2)\n",
    "\n",
    "    # no clue why I need to rotate and flip...could be investigated? \n",
    "    ax2.imshow(np.flipud(np.rot90(the_x[sample_image_start:sample_image_end], 1)), aspect = 'auto')\n",
    "\n",
    "    ax1.set_ylim(0, 80)\n",
    "    ax2.set_ylim(0, 80)\n",
    "    ax1.set_xlim(0, the_x.shape[0] / params[\"num_samples\"])\n",
    "    ax2.set_xlim(0, the_x.shape[0] / params[\"num_samples\"])\n",
    "\n",
    "    fig.tight_layout()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if params[\"record_network_ih_activity\"]:\n",
    "    # Hidden layer activity \n",
    "\n",
    "    hidden_spikes = monitor_hidden.get_data()\n",
    "\n",
    "    process = list(hidden_spikes.keys())[0]\n",
    "    spikes_out = list(hidden_spikes[process].keys())[0]\n",
    "    hidden_s = hidden_spikes[process][spikes_out]\n",
    "\n",
    "    hidden_single_image = hidden_s[sample_image_start:sample_image_end]\n",
    "\n",
    "    for i in range(params[\"NUM_HIDDEN\"]):\n",
    "        plt.scatter(np.where(hidden_single_image[:,i] > 0)[0], \n",
    "                    np.where(hidden_single_image[:,i] > 0)[0].shape[0] * [i],\n",
    "                    c = '#1f77b4',\n",
    "                    s = 0.5)\n",
    "\n",
    "    plt.title(\"Hidden layer spiking activity\")\n",
    "    plt.ylim(0, params[\"NUM_HIDDEN\"])\n",
    "    plt.xlim(0, the_x.shape[0] / params[\"num_samples\"])\n",
    "    plt.ylabel(\"layer\")\n",
    "    plt.xlabel(\"timesteps\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if params[\"record_network_ih_activity\"]:\n",
    "    # output voltage activity\n",
    "    # high voltage levels are explained by a mega high threshold, to enable non-spiking\n",
    "    output_voltage = monitor_output.get_data()\n",
    "\n",
    "    process = list(output_voltage.keys())[0]\n",
    "    spikes_out = list(output_voltage[process].keys())[0]\n",
    "    output_v = output_voltage[process][spikes_out]\n",
    "\n",
    "    single_image = output_v[sample_image_start:sample_image_end]\n",
    "\n",
    "    for i in range(params[\"NUM_OUTPUT\"]):\n",
    "        plt.plot(single_image[:,i])\n",
    "\n",
    "    plt.title(\"Output layer voltage activity\")\n",
    "    plt.ylabel(\"voltage (v)\")\n",
    "    plt.xlabel(\"timesteps\")\n",
    "    plt.xlim(0, the_x.shape[0] / params[\"num_samples\"])\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GeNN_4_9_0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
