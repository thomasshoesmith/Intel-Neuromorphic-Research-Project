{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env CUDA_PATH=/usr/local/cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import opendatasets as od\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "from ml_genn import InputLayer, Layer, SequentialNetwork, Network, Population, Connection\n",
    "from ml_genn.callbacks import Checkpoint, SpikeRecorder, VarRecorder, Callback, OptimiserParamSchedule\n",
    "from ml_genn.compilers import EventPropCompiler, InferenceCompiler\n",
    "from ml_genn.connectivity import Dense\n",
    "from ml_genn.initializers import Normal\n",
    "from ml_genn.neurons import LeakyIntegrate, LeakyIntegrateFire, SpikeInput, LeakyIntegrateFireInput\n",
    "from ml_genn.optimisers import Adam\n",
    "from ml_genn.serialisers import Numpy\n",
    "from ml_genn.synapses import Exponential\n",
    "from time import perf_counter\n",
    "\n",
    "from ml_genn.utils.data import (calc_latest_spike_time, linear_latency_encode_data)\n",
    "from ml_genn.compilers.event_prop_compiler import default_params\n",
    "\n",
    "from ml_genn.utils.data import (calc_latest_spike_time, calc_max_spikes,\n",
    "                                preprocess_tonic_spikes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_id = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kaggle dataset directory\n",
    "dataset = 'https://www.kaggle.com/datasets/thomasshoesmith/spiking-google-speech-commands/data'\n",
    "\n",
    "# Using opendatasets to download SGSC dataset\n",
    "od.download(dataset)\n",
    "\n",
    "x_test = np.load(\"spiking-google-speech-commands/testing_x_spikes.npy\", allow_pickle=True)\n",
    "y_test = np.load(\"spiking-google-speech-commands/testing_y_spikes.npy\", allow_pickle=True)\n",
    "\n",
    "\n",
    "with open(\"SC_params.json\", \"r\") as f: \n",
    "    params = json.load(f)\n",
    "\n",
    "schedule_epoch_total = 0\n",
    "\n",
    "# READ TO BE IMPLEMENTED \n",
    "# Preprocess\n",
    "x_test_spikes = []\n",
    "for i in range(len(x_test)):\n",
    "    events = x_test[i]\n",
    "    x_test_spikes.append(preprocess_tonic_spikes(events, \n",
    "                                                  x_test[0].dtype.names,\n",
    "                                                  (80, 1, 1),\n",
    "                                                  time_scale = 1))\n",
    "\n",
    "# Determine max spikes and latest spike time\n",
    "max_spikes = calc_max_spikes(x_test_spikes)\n",
    "latest_spike_time = calc_latest_spike_time(x_test_spikes)\n",
    "print(f\"Max spikes {max_spikes}, latest spike time {latest_spike_time}\")\n",
    "\n",
    "# Get number of input and output neurons from dataset \n",
    "# and round up outputs to power-of-two\n",
    "num_input = 80 #int(np.prod(x.sensor_size))\n",
    "num_output = 35 #len(x.classes)\n",
    "\n",
    "os.chdir(\"output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = \"~/PhD/Intel-Neuromorphic-Research-Project/output/full_100_epoch/\"\n",
    "\n",
    "output = pd.read_csv(os.path.expanduser(dir + \"train_output.csv\"))\n",
    "\n",
    "with open(os.path.expanduser(dir + \"params.json\"), \"r\") as f:\n",
    "        params = json.load(f)\n",
    "\n",
    "# change dir for readout files\n",
    "# lazy fix until a solution can be implemented with ml_genn to support output file directory change\n",
    "try:\n",
    "    os.makedirs(params.get(\"output_dir\") + params.get(\"sweeping_suffix\"))\n",
    "except:\n",
    "    pass\n",
    "\n",
    "os.chdir(params.get(\"output_dir\") + params.get(\"sweeping_suffix\"))\n",
    "\n",
    "\n",
    "\n",
    "serialiser = Numpy(os.path.expanduser(dir + \"/SC\"))\n",
    "network = Network(default_params)\n",
    "    \n",
    "with network:\n",
    "    # Populations\n",
    "    input = Population(SpikeInput(max_spikes = params[\"BATCH_SIZE\"] * max_spikes),\n",
    "                       num_input,\n",
    "                       record_spikes=True)\n",
    "    \n",
    "    hidden = Population(LeakyIntegrateFire(v_thresh=1.0, \n",
    "                                    tau_mem=20.0),\n",
    "                params.get(\"NUM_HIDDEN\"), \n",
    "                record_spikes=True)\n",
    "    \n",
    "    output = Population(LeakyIntegrate(tau_mem=20.0, \n",
    "                                readout=\"avg_var_exp_weight\"),\n",
    "                params.get(\"NUM_OUTPUT\"), \n",
    "                record_spikes=True)\n",
    "\n",
    "    Connection(input, hidden, Dense(Normal(mean = params.get(\"input_hidden_w_mean\"), \n",
    "                                            sd = params.get(\"input_hidden_w_sd\"))),\n",
    "                Exponential(2.0))\n",
    "    \n",
    "    if params.get(\"recurrent\"):\n",
    "        Connection(hidden, hidden, Dense(Normal(mean = params.get(\"hidden_hidden_w_mean\"), \n",
    "                                                sd = params.get(\"hidden_hidden_w_sd\"))),\n",
    "                Exponential(2.0))\n",
    "    \n",
    "    Connection(hidden, output, Dense(Normal(mean = params.get(\"hidden_output_w_mean\"),\n",
    "                                sd = params.get(\"hidden_output_w_sd\"))),\n",
    "                Exponential(2.0))\n",
    "\n",
    "network.load((params.get(\"NUM_EPOCH\") - 1,), serialiser)\n",
    "\n",
    "compiler = InferenceCompiler(evaluate_timesteps = params.get(\"NUM_FRAMES\") * params.get(\"INPUT_FRAME_TIMESTEP\"),\n",
    "                            reset_in_syn_between_batches=True,\n",
    "                            #quantise_num_weight_bits=8,\n",
    "                            #quantise_weight_percentile=99,\n",
    "                            batch_size = params.get(\"BATCH_SIZE\"))\n",
    "compiled_net = compiler.compile(network)\n",
    "\n",
    "with compiled_net:\n",
    "\n",
    "    callbacks = [SpikeRecorder(input, \n",
    "                               key = \"input_spikes\",\n",
    "                               example_filter = sample_id),\n",
    "                 SpikeRecorder(hidden,\n",
    "                               key = \"hidden_spikes\",\n",
    "                               example_filter = sample_id),\n",
    "                 VarRecorder(output, \n",
    "                             var = \"v\",\n",
    "                             key = \"output_voltages\",\n",
    "                             example_filter = sample_id)]\n",
    "\n",
    "    metrics, cb_data = compiled_net.evaluate({input: x_test_spikes},\n",
    "                                             {output: y_test},\n",
    "                                             callbacks = callbacks)\n",
    "    \n",
    "    #compiled_net.save((\"quant8\",), serialiser)\n",
    "\n",
    "    print(f\"Accuracy = {100 * metrics[output].result}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input spike activity\n",
    "plt.title('Input Spikes (with raw input for comparison) from lava')\n",
    "\n",
    "plt.scatter(cb_data[\"input_spikes\"][0][0], cb_data[\"input_spikes\"][1][0],\n",
    "            s = 1)\n",
    "\n",
    "# no clue why I need to rotate and flip...could be investigated? \n",
    "\n",
    "plt.ylim(0, 80)\n",
    "plt.xlim(0, 2000)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(cb_data[\"hidden_spikes\"][0][0], cb_data[\"hidden_spikes\"][1][0],\n",
    "            s = 0.5)\n",
    "plt.ylabel(\"neurons\")\n",
    "plt.xlabel(\"timesteps\")\n",
    "plt.title(\"Hidden layer activity\")\n",
    "plt.ylim(0, 512)\n",
    "plt.xlim(0, 2000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(cb_data[\"output_voltages\"][0])\n",
    "plt.ylabel(\"voltage (v)\")\n",
    "plt.xlabel(\"timesteps\")\n",
    "plt.title(\"output voltage activity\")\n",
    "plt.xlim(0, 2000)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genn_4_9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
