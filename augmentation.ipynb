{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For the creation of augmentation algorithms to be used in the EventProp HD model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset and visualise for development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "from tqdm import trange\n",
    "\n",
    "import random\n",
    "\n",
    "import imageio as iio\n",
    "from skimage import filters\n",
    "from skimage.color import rgb2gray  # only needed for incorrectly saved images\n",
    "from skimage.measure import regionprops\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = os.path.expanduser(\"~/data/rawHD/experimental_2/\")\n",
    "x_train = np.load(file_path + \"training_x_data.npy\")\n",
    "y_train = np.load(file_path + \"training_y_data.npy\")\n",
    "\n",
    "training_images = x_train + abs(np.floor(x_train.min()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shift_y_axis(image_array, shift_value = np.random.randint(-5, 5)):\n",
    "    \n",
    "    new_image_array = copy.deepcopy(image_array)\n",
    "    \n",
    "    if shift_value > 0:\n",
    "        new_image_array[0: -shift_value, :] = image_array[shift_value:,:]\n",
    "        new_image_array[-shift_value:,:] = 0\n",
    "    \n",
    "    if shift_value < 0:\n",
    "        new_image_array[-shift_value:, :] = image_array[0: shift_value, :]\n",
    "        new_image_array[0:-shift_value, :] = 0\n",
    "        \n",
    "    return new_image_array\n",
    "\n",
    "\n",
    "def shift_x_axis(image_array, shift_value = np.random.randint(-5, 5)):\n",
    "    \n",
    "    new_image_array = copy.deepcopy(image_array)\n",
    "    \n",
    "    if shift_value > 0:\n",
    "        new_image_array[0: ,shift_value:] = image_array[:,: -shift_value]\n",
    "        new_image_array[:, :shift_value] = 0\n",
    "    \n",
    "    if shift_value < 0:\n",
    "        new_image_array[:,:shift_value] = image_array[:,-shift_value:]\n",
    "        new_image_array[:,shift_value:] = 0\n",
    "        \n",
    "    return new_image_array\n",
    "\n",
    "\n",
    "def neighbour_swap(image_array, pSwap = 0.2, kSwap = 3):\n",
    "    new_image_array = copy.deepcopy(image_array)\n",
    "    \n",
    "    for x in range(image_array.shape[0]):\n",
    "        for y in range(image_array.shape[1]):\n",
    "            if np.random.uniform() > pSwap:\n",
    "                k = np.random.randint(-kSwap, kSwap, 2)\n",
    "                kx, ky = x + k[0], y + k[1]\n",
    "                \n",
    "                if kx > -1 and kx < image_array.shape[0] and ky > -1 and ky < image_array.shape[1]:\n",
    "                    new_image_array[kx, ky] = image_array[x, y]\n",
    "    \n",
    "    return new_image_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shifting in the y axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = copy.deepcopy(training_images[0])\n",
    "shift = np.random.randint(-5, 5)\n",
    "\n",
    "new_x_train = shift_y_axis(x_train, shift)\n",
    "    \n",
    "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "\n",
    "ax1.set_title(\"before\")\n",
    "ax1.imshow(x_train)\n",
    "ax1.axis(\"off\")\n",
    "\n",
    "ax2.set_title(f\"after a shift of {shift}\")\n",
    "ax2.imshow(new_x_train)\n",
    "ax2.axis(\"off\")\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (15, 10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shifting in the x axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = copy.deepcopy(training_images[0])\n",
    "shift = np.random.randint(-5, 5)\n",
    "\n",
    "new_x_train = shift_x_axis(x_train, shift)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "\n",
    "ax1.set_title(\"before\")\n",
    "ax1.imshow(x_train)\n",
    "ax1.axis(\"off\")\n",
    "\n",
    "ax2.set_title(f\"after a shift of {shift}\")\n",
    "ax2.imshow(new_x_train)\n",
    "ax2.axis(\"off\")\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (15, 10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### adding noise to the data (neighbour swapping)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = training_images[0]\n",
    "pSwap = 0.2 #swap probability\n",
    "kSwap = 3 #distance of neighbour swap\n",
    "\n",
    "new_x_train = neighbour_swap(x_train)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "\n",
    "ax1.set_title(\"before\")\n",
    "ax1.imshow(x_train)\n",
    "ax1.axis(\"off\")\n",
    "\n",
    "ax2.set_title(f\"after shift of {pSwap} probability and {kSwap} neighbours\")\n",
    "ax2.imshow(new_x_train)\n",
    "ax2.axis(\"off\")\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (15, 10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### blending classes for new image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort x training images into y categories for blending\n",
    "categories = [[] for i in range(np.max(y_train) + 1)]\n",
    "\n",
    "for i in trange(y_train.shape[0]):\n",
    "    categories[y_train[i]].append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.load(file_path + \"training_x_data.npy\")\n",
    "class_digit = 11\n",
    "x_train = x_train[categories[class_digit][np.random.randint(0, len(categories[class_digit]))]]\n",
    "\n",
    "\n",
    "def get_image_center_of_mass(image_array):\n",
    "    threshold_value = filters.threshold_otsu(image_array)\n",
    "    labeled_foreground = (image_array > threshold_value).astype(int)\n",
    "    properties = regionprops(labeled_foreground, image_array)\n",
    "    center_of_mass = properties[0].centroid\n",
    "    weighted_center_of_mass = properties[0].weighted_centroid\n",
    "    return center_of_mass, weighted_center_of_mass\n",
    "\n",
    "center_of_mass, weighted_center_of_mass = get_image_center_of_mass(x_train)\n",
    "print(center_of_mass)\n",
    "plt.rcParams[\"figure.figsize\"] = (10, 8)\n",
    "plt.imshow(x_train)\n",
    "plt.axhline(np.round(center_of_mass[0]), c = \"r\")\n",
    "plt.axvline(np.round(center_of_mass[1]), c = \"r\")\n",
    "plt.axhline(np.round(weighted_center_of_mass[0]), c = \"b\")\n",
    "plt.axvline(np.round(weighted_center_of_mass[1]), c = \"b\")\n",
    "plt.show()\n",
    "\n",
    "# Getting the central mass of the image\n",
    "plt.rcParams[\"figure.figsize\"] = (10, 8)\n",
    "flattened = np.sum(x_train, axis = 0)\n",
    "plt.plot(flattened)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image1 = training_images[categories[0][0]]\n",
    "image2 = training_images[categories[0][1]]\n",
    "\n",
    "plt.imshow(image1)\n",
    "plt.show()\n",
    "plt.imshow(image2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### PROOF ###\n",
    "\n",
    "random_class = np.random.randint(0, 19)\n",
    "random_trial1 = np.random.randint(0, 300)\n",
    "random_trial2 = np.random.randint(0, 300)\n",
    "\n",
    "com_or_wcom = 0\n",
    "\n",
    "image1 = training_images[categories[random_class][random_trial1]]\n",
    "image2 = training_images[categories[random_class][random_trial2]]\n",
    "\n",
    "com1 = np.round(get_image_center_of_mass(image1)[com_or_wcom])\n",
    "com2 = np.round(get_image_center_of_mass(image2)[com_or_wcom])\n",
    "\n",
    "print(f\"center of mass for image 1: {com1}\")\n",
    "print(f\"center of mass for image 2: {com2}\")\n",
    "\n",
    "difference = np.round(np.mean([com1, com2], axis = 0))\n",
    "\n",
    "print(f\"average between both images is {difference}\")\n",
    "\n",
    "print(f\"difference between image 1 is {difference - com1}\")\n",
    "print(f\"difference between image 2 is {difference - com2}\")\n",
    "\n",
    "new_image1 = shift_y_axis(shift_x_axis(image1, int((difference - com1)[1])), int((difference - com1)[0]))\n",
    "\n",
    "new_image2 = shift_y_axis(shift_x_axis(image2, int((difference - com2)[1])), int((difference - com2)[0]))\n",
    "\n",
    "plt.imshow(new_image1)\n",
    "plt.axhline(difference[0], c = \"r\")\n",
    "plt.axvline(difference[1], c = \"r\", label = \"average\")\n",
    "plt.axhline((com1[0] + int((difference - com1)[0])), linestyle = \"--\", c = \"b\")\n",
    "plt.axvline((com1[1] + int((difference - com1)[1])), linestyle = \"--\", c = \"b\", label = \"centre of mass\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(new_image2)\n",
    "plt.axhline(difference[0], c = \"r\")\n",
    "plt.axvline(difference[1], c = \"r\", label = \"average\")\n",
    "plt.axhline((com2[0] + int((difference - com2)[0])), linestyle = \"--\", c = \"b\")\n",
    "plt.axvline((com2[1] + int((difference - com2)[1])), linestyle = \"--\", c = \"b\", label = \"centre of mass\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merging the two images into one\n",
    "\n",
    "combined_image = copy.deepcopy(new_image1)\n",
    "\n",
    "for y in range(new_image1.shape[0]):\n",
    "    for x in range(new_image1.shape[1]):\n",
    "        p = np.random.uniform()\n",
    "        if p > 0.5:\n",
    "            combined_image[y, x] = new_image2[y, x]\n",
    "            \n",
    "            \n",
    "plt.imshow(combined_image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merging the two images into one\n",
    "\n",
    "combined_image = copy.deepcopy(new_image1)\n",
    "\n",
    "for y in range(new_image1.shape[0]):\n",
    "    for x in range(new_image1.shape[1]):\n",
    "        combined_image[y, x] = (combined_image[y, x] + new_image2[y, x] / 2)\n",
    "            \n",
    "            \n",
    "plt.imshow(combined_image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_two_images(image_array_1, image_array_2, com_or_wcom = 0):\n",
    "    \"\"\"\n",
    "    To combine two images by averaging them together\n",
    "\n",
    "    :param image_array_1: first image\n",
    "    :param image_array_2: second image\n",
    "    :param com_or_wcom: centre of mass or weighted centre of mass\n",
    "    :return: image array of combined images\n",
    "    \"\"\"\n",
    "\n",
    "    com1 = np.round(get_image_center_of_mass(image_array_1)[com_or_wcom])\n",
    "    com2 = np.round(get_image_center_of_mass(image_array_2)[com_or_wcom])\n",
    "\n",
    "    difference = np.round(np.mean([com1, com2], axis = 0))\n",
    "\n",
    "    new_image1 = shift_y_axis(shift_x_axis(image_array_1, int((difference - com1)[1])), int((difference - com1)[0]))\n",
    "    new_image2 = shift_y_axis(shift_x_axis(image_array_2, int((difference - com2)[1])), int((difference - com2)[0]))\n",
    "    \n",
    "    combined_image = copy.deepcopy(new_image1)\n",
    "\n",
    "    for y in range(new_image1.shape[0]):\n",
    "        for x in range(new_image1.shape[1]):\n",
    "            combined_image[y, x] = (combined_image[y, x] + new_image2[y, x] / 2)\n",
    "    \n",
    "    return combined_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.load(file_path + \"training_x_data.npy\")\n",
    "y_train = np.load(file_path + \"training_y_data.npy\")\n",
    "training_images = x_train + abs(np.floor(x_train.min()))\n",
    "\n",
    "# sort x training images into y categories for blending\n",
    "categories = [[] for i in range(np.max(y_train) + 1)]\n",
    "\n",
    "for i in trange(y_train.shape[0]):\n",
    "    categories[y_train[i]].append(i)\n",
    "    \n",
    "combined_image_array = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for spoken_word in trange(len(categories)):\n",
    "\n",
    "    random.shuffle(categories[spoken_word])\n",
    "\n",
    "    while len(categories[spoken_word]) > 1:\n",
    "        image1 = training_images[categories[spoken_word][0]]\n",
    "        image2 = training_images[categories[spoken_word][1]]\n",
    "        \n",
    "        combined_image_array.append(combine_two_images(image1, image2))\n",
    "        categories[spoken_word].pop()\n",
    "        categories[spoken_word].pop()\n",
    "\n",
    "        #print(f\"images left: {len(categories[spoken_word])} | new generated images: {len(combined_image_array)}\")\n",
    "        \n",
    "plt.imshow(combined_image_array[-1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import augmentation_tools\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import trange\n",
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = os.path.expanduser(\"~/data/rawHD/experimental_2/\")\n",
    "x_train = np.load(file_path + \"training_x_data.npy\")\n",
    "y_train = np.load(file_path + \"training_y_data.npy\")\n",
    "training_images = x_train + abs(np.floor(x_train.min()))\n",
    "\n",
    "# sort x training images into y categories for blending\n",
    "categories = [[] for i in range(np.max(y_train) + 1)]\n",
    "\n",
    "for i in range(y_train.shape[0]):\n",
    "    categories[y_train[i]].append(i)\n",
    "    \n",
    "combined_image_array = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for spoken_word in trange(len(categories)):\n",
    "\n",
    "    random.shuffle(categories[spoken_word])\n",
    "\n",
    "    while len(categories[spoken_word]) > 1:\n",
    "        image1 = training_images[categories[spoken_word][0]]\n",
    "        image2 = training_images[categories[spoken_word][1]]\n",
    "        \n",
    "        combined_image_array.append(augmentation_tools.combine_two_images(image1, image2))\n",
    "        categories[spoken_word].pop()\n",
    "        categories[spoken_word].pop()\n",
    "\n",
    "        #print(f\"images left: {len(categories[spoken_word])} | new generated images: {len(combined_image_array)}\")\n",
    "        \n",
    "plt.imshow(combined_image_array[-1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import augmentation_tools\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import trange\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "file_path = os.path.expanduser(\"~/data/rawHD/experimental_2/\")\n",
    "x_train = np.load(file_path + \"training_x_data.npy\")\n",
    "y_train = np.load(file_path + \"training_y_data.npy\")\n",
    "training_images = x_train + abs(np.floor(x_train.min()))\n",
    "\n",
    "# sort x training images into y categories for blending\n",
    "categories = [[] for i in range(np.max(y_train) + 1)]\n",
    "\n",
    "for i in range(y_train.shape[0]):\n",
    "    categories[y_train[i]].append(i)\n",
    "    \n",
    "combined_image_array = []\n",
    "combined_class_array = []\n",
    "\n",
    "for spoken_word in trange(len(categories)):\n",
    "\n",
    "    random.shuffle(categories[spoken_word])\n",
    "\n",
    "    while len(categories[spoken_word]) > 1:\n",
    "        image1 = training_images[categories[spoken_word][0]]\n",
    "        image2 = training_images[categories[spoken_word][1]]\n",
    "        \n",
    "        combined_image_array.append(augmentation_tools.combine_two_images(image1, image2))\n",
    "        categories[spoken_word].pop()\n",
    "        categories[spoken_word].pop()\n",
    "        \n",
    "        combined_class_array.append(spoken_word)\n",
    "\n",
    "        #print(f\"images left: {len(categories[spoken_word])} | new generated images: {len(combined_image_array)}\")\n",
    "        \n",
    "plt.imshow(combined_image_array[-1])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(combined_image_array).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import augmentation_tools\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import trange\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "file_path = os.path.expanduser(\"~/data/rawHD/experimental_2/\")\n",
    "x_train = np.load(file_path + \"training_x_data.npy\")\n",
    "y_train = np.load(file_path + \"training_y_data.npy\")\n",
    "training_images = x_train + abs(np.floor(x_train.min()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_two_images_and_concatinate(training_images, training_labels):\n",
    "    # sort x training images into y categories for blending\n",
    "    categories = [[] for i in range(np.max(training_labels) + 1)]\n",
    "\n",
    "    for i in range(training_labels.shape[0]):\n",
    "        categories[training_labels[i]].append(i)\n",
    "        \n",
    "    combined_image_array = []\n",
    "    combined_class_array = []\n",
    "\n",
    "    for spoken_word in trange(len(categories)):\n",
    "\n",
    "        random.shuffle(categories[spoken_word])\n",
    "\n",
    "        while len(categories[spoken_word]) > 1:\n",
    "            image1 = training_images[categories[spoken_word][0]]\n",
    "            image2 = training_images[categories[spoken_word][1]]\n",
    "            \n",
    "            combined_image_array.append(augmentation_tools.combine_two_images(image1, image2))\n",
    "            categories[spoken_word].pop()\n",
    "            categories[spoken_word].pop()\n",
    "            \n",
    "            combined_class_array.append(spoken_word)\n",
    "    \n",
    "    combined_training_images = np.concatenate([training_images, \n",
    "                                               np.array(combined_image_array)])\n",
    "    \n",
    "    combined_training_labels = np.concatenate([training_labels,\n",
    "                                               np.array(combined_class_array)])\n",
    "    \n",
    "    return combined_training_images, combined_training_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cti = augmentation_tools.combine_two_images_and_concatinate(training_images, y_train)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cti.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genn_4_8_1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
