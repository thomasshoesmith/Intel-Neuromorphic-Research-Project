{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Google Speech Command Encoding with Mel-Spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import librosa.display\n",
    "import IPython.display as ipd\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "import re\n",
    "from tqdm import trange\n",
    "import copy\n",
    "import hashlib\n",
    "\n",
    "import scipy.io.wavfile\n",
    "from scipy.fftpack import dct\n",
    "import soundfile as sf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# navigate to folder where http://download.tensorflow.org/data/speech_commands_v0.01.tar.gz is downloaded\n",
    "os.chdir(\"/its/home/ts468/data/GSC/speech_commands/\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load GSC validation and training data list\n",
    "\n",
    "# load a list of training audio files\n",
    "validation_files = []\n",
    "with open(\"validation_list.txt\", \"r\") as file:\n",
    "    for line in file:\n",
    "        x = line[:-1]\n",
    "        validation_files.append(x)\n",
    "        \n",
    "# load a list of testing audio files\n",
    "test_files = []\n",
    "with open(\"testing_list.txt\", \"r\") as file:\n",
    "    for line in file:\n",
    "        x = line[:-1]\n",
    "        test_files.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View sound file\n",
    "\n",
    "print(\"file format: \", test_files[0])\n",
    "ipd.Audio(test_files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load classes and assign labels\n",
    "\n",
    "folders = os.listdir()\n",
    "exception = [\"validation_list.txt\",\n",
    "             \"_background_noise_\",\n",
    "             \".DS_Store\",\n",
    "             \"README.md\",\n",
    "             \"LICENSE\",\n",
    "             \"testing_list.txt\"]\n",
    "\n",
    "assert len(list(set(folders) - set(exception))) == 35\n",
    "\n",
    "classes = np.sort(list(set(folders) - set(exception)))\n",
    "\n",
    "classes_and_labels = {}\n",
    "\n",
    "for i, c in enumerate(classes):\n",
    "    classes_and_labels[c] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_mel_spectrogram(file_name, display = False, steps = 80):\n",
    "    # load audio files with librosa\n",
    "    signal, sr = librosa.load(file_name)\n",
    "\n",
    "    # pre-emphasis filter\n",
    "    alpha =  .95\n",
    "    emphasized_signal = np.append(signal[0], signal[1:] - alpha * signal[:-1])\n",
    "    \n",
    "    # framing\n",
    "    frame_size = .025\n",
    "    frame_stride = .01\n",
    "\n",
    "    frame_length, frame_step = frame_size * sr, frame_stride * sr  # Convert from seconds to samples\n",
    "    signal_length = len(emphasized_signal)\n",
    "    frame_length = int(round(frame_length))\n",
    "    frame_step = int(round(frame_step))\n",
    "    num_frames = int(np.ceil(float(np.abs(signal_length - frame_length)) / frame_step))  # Make sure that we have at least 1 frame\n",
    "\n",
    "    pad_signal_length = num_frames * frame_step + frame_length\n",
    "    z = np.zeros((pad_signal_length - signal_length))\n",
    "    pad_signal = np.append(emphasized_signal, z) # Pad Signal to make sure that all frames have equal number of samples without truncating any samples from the original signal\n",
    "\n",
    "    indices = np.tile(np.arange(0, frame_length), (num_frames, 1)) + np.tile(np.arange(0, num_frames * frame_step, frame_step), (frame_length, 1)).T\n",
    "    frames = pad_signal[indices.astype(np.int32, copy=False)]\n",
    "    \n",
    "    # Hamming window\n",
    "    frames *= np.hamming(frame_length)\n",
    "    \n",
    "    # fast Fourier-Transform and Power Spectrum\n",
    "    NFFT = 512\n",
    "    mag_frames = np.absolute(np.fft.rfft(frames, NFFT))  # Magnitude of the FFT\n",
    "    pow_frames = ((1.0 / NFFT) * ((mag_frames) ** 2))  # Power Spectrum\n",
    "    \n",
    "    # filter banks\n",
    "    nfilt = 40\n",
    "    low_freq_mel = 0\n",
    "    high_freq_mel = (2595 * np.log10(1 + (sr / 2) / 700))  # Convert Hz to Mel\n",
    "    mel_points = np.linspace(low_freq_mel, high_freq_mel, nfilt + 2)  # Equally spaced in Mel scale\n",
    "    hz_points = (700 * (10**(mel_points / 2595) - 1))  # Convert Mel to Hz\n",
    "    bin = np.floor((NFFT + 1) * hz_points / sr)\n",
    "\n",
    "    fbank = np.zeros((nfilt, int(np.floor(NFFT / 2 + 1))))\n",
    "    for m in range(1, nfilt + 1):\n",
    "        f_m_minus = int(bin[m - 1])   # left\n",
    "        f_m = int(bin[m])             # center\n",
    "        f_m_plus = int(bin[m + 1])    # right\n",
    "\n",
    "        for k in range(f_m_minus, f_m):\n",
    "            fbank[m - 1, k] = (k - bin[m - 1]) / (bin[m] - bin[m - 1])\n",
    "        for k in range(f_m, f_m_plus):\n",
    "            fbank[m - 1, k] = (bin[m + 1] - k) / (bin[m + 1] - bin[m])\n",
    "    filter_banks = np.dot(pow_frames, fbank.T)\n",
    "    filter_banks = np.where(filter_banks == 0, np.finfo(float).eps, filter_banks)  # Numerical Stability\n",
    "    filter_banks = 20 * np.log10(filter_banks)  # dB\n",
    "\n",
    "    \n",
    "    # Crop or pad to 80 steps by repeating the last frame\n",
    "    target_steps = steps\n",
    "    current_steps = filter_banks.shape[0]\n",
    "    if current_steps < target_steps:\n",
    "        padding = np.tile(filter_banks[-1, :], (target_steps - current_steps, 1))\n",
    "        filter_banks = np.vstack((filter_banks, padding))\n",
    "    elif current_steps > target_steps:\n",
    "        filter_banks = filter_banks[:target_steps, :]\n",
    "    \n",
    "    # todo: this is a fix to allow output to match input...  \n",
    "    filter_banks = np.rot90(filter_banks)\n",
    "    filter_banks = np.flipud(filter_banks)\n",
    "    \n",
    "    if display:\n",
    "        # Display the filter banks with the 'viridis' colormap\n",
    "        plt.figure(figsize=(10, 4))\n",
    "        librosa.display.specshow(filter_banks, x_axis='time', y_axis='mel', sr=sr, cmap='viridis')\n",
    "        plt.colorbar(format='%+2.0f dB')\n",
    "        plt.title('Mel Filter Banks with Pre-Emphasis Filter (Cropped/Padded to 80 Steps)')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        print(filter_banks.shape)\n",
    "    \n",
    "    else:\n",
    "        return filter_banks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise the output of the mel encoding\n",
    "\n",
    "test_image = test_files[1230]\n",
    "to_mel_spectrogram(test_image, True, 100)\n",
    "\n",
    "# Visualise the same input but on soecgram (visual check)\n",
    "data, samplerate = sf.read(test_image)  \n",
    "Pxx, freqs, bins, im = plt.specgram(data, Fs=samplerate)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all files to loop through\n",
    "\n",
    "all_files = []\n",
    "\n",
    "for folder in list(set(folders) - set(exception)):\n",
    "    files_in_folder = os.listdir(folder)\n",
    "    for sound_file in files_in_folder:\n",
    "        all_files.append(folder + \"/\" + sound_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_x_data = []\n",
    "training_y_data = []\n",
    "testing_x_data = []\n",
    "testing_y_data = []\n",
    "validation_x_data = []\n",
    "validation_y_data = []\n",
    "\n",
    "# save all to a list\n",
    "for i in trange(len(all_files)):\n",
    "    \n",
    "    if all_files[i] in validation_files:\n",
    "        validation_x_data.append(copy.deepcopy(to_mel_spectrogram(all_files[i])))\n",
    "        validation_y_data.append(int(classes_and_labels[re.split(\"[/]\", all_files[i])[0]]))\n",
    "\n",
    "    if all_files[i] in test_files:\n",
    "        testing_x_data.append(copy.deepcopy(to_mel_spectrogram(all_files[i])))\n",
    "        testing_y_data.append(int(classes_and_labels[re.split(\"[/]\", all_files[i])[0]]))\n",
    "        \n",
    "    else:\n",
    "        training_x_data.append(copy.deepcopy(to_mel_spectrogram(all_files[i])))\n",
    "        training_y_data.append(int(classes_and_labels[re.split(\"[/]\", all_files[i])[0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(training_x_data))\n",
    "print(len(testing_x_data))\n",
    "print(len(validation_x_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save dataset\n",
    "\n",
    "# TODO: update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# navigate to folder to save encoded data\n",
    "os.chdir(\"/its/home/ts468/data/GSC/experimental_1\")\n",
    "print(\"current cwd\", os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"training_x_data.npy\", training_x_data)\n",
    "np.save(\"training_y_data.npy\", training_y_data)\n",
    "np.save(\"testing_x_data.npy\", testing_x_data)\n",
    "np.save(\"testing_y_data.npy\", testing_y_data)\n",
    "np.save(\"validation_x_data.npy\", validation_x_data)\n",
    "np.save(\"validation_y_data.npy\", validation_y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pythonenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
