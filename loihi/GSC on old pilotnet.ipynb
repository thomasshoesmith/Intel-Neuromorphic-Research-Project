{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "mature-massage",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import lava.lib.dl.slayer as slayer\n",
    "\n",
    "from gsc_dataset import GSCDataset\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "expressed-juice",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f3aafe43b70>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(4205)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dying-strength",
   "metadata": {},
   "source": [
    "# Event sparsity loss\n",
    "\n",
    "Sparsity loss to penalize the network for high event-rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "nonprofit-charger",
   "metadata": {},
   "outputs": [],
   "source": [
    "def event_rate_loss(x, max_rate=0.01):\n",
    "    mean_event_rate = torch.mean(torch.abs(x))\n",
    "    return F.mse_loss(F.relu(mean_event_rate - max_rate), torch.zeros_like(mean_event_rate))\n",
    "\n",
    "def loss(output, target):\n",
    "    return F.mse_loss(output, target.to(\"cpu\")) #TODO: CUDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comfortable-corrections",
   "metadata": {},
   "source": [
    "# Network description\n",
    "\n",
    "__SLAYER 2.0__ (__`lava.dl.slayer`__) provides a variety of learnable _neuron models_ <!-- (`slayer.neuron.{cuba, rf, ad_lif, __sigma_delta__, ...}`)  --> , _synapses_ <!-- (`slayer.{synapse, complex.synapse}.{dense, conv, pool, convT, unpool}`)  --> _axons_ and _dendrites_ that support quantized training. \n",
    "For easier use, it also provides __`block`__ interface which packages the associated neurons, synapses, axons and dendrite features into a single module. \n",
    "\n",
    "__Sigma-delta blocks__ are available as `slayer.blocks.sigma_delta.{Dense, Conv, Pool, Input, Output, Flatten, ...}` which can be easily composed to create a variety of sequential network descriptions as shown below. The blocks can easily enable _synaptic weight normalization_, _neuron normalization_ as well as provide useful _gradient monitoring_ utility and _hdf5 network export_ utility.\n",
    "\n",
    "<!-- TODO:\n",
    "- Describe how easy it is to describe a network in slayer2.0\n",
    "- Parameter Quantization is automatically handled unless disabled\n",
    "- Weight and neuron normalization\n",
    "- gradient monitoring utility\n",
    "- hdf5 export utility -->\n",
    "\n",
    "These blocks can be used to create a network using standard PyTorch procedure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "mature-doubt",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Network, self).__init__()\n",
    "        \n",
    "        cuba_params = {\n",
    "                'threshold'    : 1.25, \n",
    "                'current_decay': 0.25, \n",
    "                'voltage_decay': 0.25, \n",
    "                'tau_grad'     : 0.1,\n",
    "                'scale_grad'   : 0.8,\n",
    "                'shared_param' : False, \n",
    "                'requires_grad': False, \n",
    "                'graded_spike' : False,\n",
    "            }\n",
    "\n",
    "        recurr_weight_scale = 1.0\n",
    "\n",
    "        self.blocks = torch.nn.ModuleList([\n",
    "                # layer 1\n",
    "                slayer.block.cuba.Dense(cuba_params, 80, 512, weight_scale=recurr_weight_scale),\n",
    "                slayer.block.cuba.Dense(cuba_params, 512, 35, weight_scale=1.0)\n",
    "                #slayer.block.cuba.Average(num_outputs=35) #TODO 35\n",
    "            ])\n",
    "\n",
    "        \n",
    "    def forward(self, spike):\n",
    "        count = []\n",
    "\n",
    "        for block in self.blocks:\n",
    "            # print(block)\n",
    "            # print(f'{block=}')\n",
    "            spike = block(spike)\n",
    "            # print(\"spike computed\")\n",
    "            if self.count_calc:\n",
    "                count.append(torch.mean(spike).item())\n",
    "                if np.isnan(count[-1]):\n",
    "                    print(spike)\n",
    "                    return spike, None\n",
    "\n",
    "        return (\n",
    "            torch.mean(spike, dim=-1), \n",
    "            torch.FloatTensor(count).reshape((1, -1)).to(spike.get_device()) if self.count_calc else None,)\n",
    "    \n",
    "\n",
    "    def grad_flow(self, path):\n",
    "        # helps monitor the gradient flow\n",
    "        grad = [b.synapse.grad_norm for b in self.blocks if hasattr(b, 'synapse')]\n",
    "\n",
    "        plt.figure()\n",
    "        plt.semilogy(grad)\n",
    "        plt.savefig(path + 'gradFlow.png')\n",
    "        plt.close()\n",
    "\n",
    "        return grad\n",
    "    \n",
    "    def export_hdf5(self, filename):\n",
    "        # network export to hdf5 format\n",
    "        h = h5py.File(filename, 'w')\n",
    "        layer = h.create_group('layer')\n",
    "        for i, b in enumerate(self.blocks):\n",
    "            b.export_hdf5(layer.create_group(f'{i}'))\n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "closed-willow",
   "metadata": {},
   "source": [
    "# Training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "brown-twins",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch  = 8  # batch size\n",
    "lr     = 0.001 # leaerning rate\n",
    "lam    = 0.01  # lagrangian for event rate loss\n",
    "epochs = 20  # training epochs\n",
    "steps  = [60, 120, 160] # learning rate reduction milestones\n",
    "\n",
    "trained_folder = 'Trained'\n",
    "logs_folder = 'Logs'\n",
    "\n",
    "os.makedirs(trained_folder, exist_ok=True)\n",
    "os.makedirs(logs_folder   , exist_ok=True)\n",
    "\n",
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a88e226",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset not available locally. Starting download ...\n",
      "wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1Ue4XohCOV5YXy57S_5tDfCVqzLr101M7' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1Ue4XohCOV5YXy57S_5tDfCVqzLr101M7\" -O data/driving_dataset.zip && rm -rf /tmp/cookies.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--2024-04-19 06:22:44--  https://docs.google.com/uc?export=download&confirm=&id=1Ue4XohCOV5YXy57S_5tDfCVqzLr101M7\n",
      "Resolving docs.google.com (docs.google.com)... 142.251.211.238, 2607:f8b0:400a:804::200e\n",
      "Connecting to docs.google.com (docs.google.com)|142.251.211.238|:443... connected.\n",
      "HTTP request sent, awaiting response... 303 See Other\n",
      "Location: https://drive.usercontent.google.com/download?id=1Ue4XohCOV5YXy57S_5tDfCVqzLr101M7&export=download [following]\n",
      "--2024-04-19 06:22:44--  https://drive.usercontent.google.com/download?id=1Ue4XohCOV5YXy57S_5tDfCVqzLr101M7&export=download\n",
      "Resolving drive.usercontent.google.com (drive.usercontent.google.com)... 142.250.217.97, 2607:f8b0:400a:80b::2001\n",
      "Connecting to drive.usercontent.google.com (drive.usercontent.google.com)|142.250.217.97|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 2431 (2.4K) [text/html]\n",
      "Saving to: ‘data/driving_dataset.zip’\n",
      "\n",
      "     0K ..                                                    100% 65.6M=0s\n",
      "\n",
      "2024-04-19 06:22:44 (65.6 MB/s) - ‘data/driving_dataset.zip’ saved [2431/2431]\n",
      "\n",
      "  End-of-central-directory signature not found.  Either this file is not\n",
      "  a zipfile, or it constitutes one disk of a multi-part archive.  In the\n",
      "  latter case the central directory and zipfile comment will be found on\n",
      "  the last disk(s) of this archive.\n",
      "unzip:  cannot find zipfile directory in one of data/driving_dataset.zip or\n",
      "        data/driving_dataset.zip.zip, and cannot find data/driving_dataset.zip.ZIP, period.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download complete.\n",
      "Extracting data (this may take a while) ...\n",
      "Could not extract file data/driving_dataset.zip. Please extract it manually.\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/driving_dataset/data.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Datasets\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m training_set \u001b[38;5;241m=\u001b[39m \u001b[43mGSCDataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtransform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransforms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompose\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtransforms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mToTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Intel-Neuromorphic-Research-Project/loihi/gsc_dataset.py:95\u001b[0m, in \u001b[0;36mGSCDataset.__init__\u001b[0;34m(self, path, sequence, train, visualize, transform, extract, download)\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(path \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/driving_dataset.zip\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m     93\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(download_msg)\n\u001b[0;32m---> 95\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata.txt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m data:\n\u001b[1;32m     96\u001b[0m     all_samples \u001b[38;5;241m=\u001b[39m [line\u001b[38;5;241m.\u001b[39msplit() \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m data]\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msamples \u001b[38;5;241m=\u001b[39m all_samples\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/driving_dataset/data.txt'"
     ]
    }
   ],
   "source": [
    "# Datasets\n",
    "training_set = GSCDataset(\n",
    "    train=True, \n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "    ]), \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hidden-spring",
   "metadata": {},
   "source": [
    "# Instantiate Network, Optimizer, Dataset and Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exposed-claim",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Network().to(device)\n",
    "\n",
    "optimizer = torch.optim.RAdam(net.parameters(), lr=lr, weight_decay=1e-5)\n",
    "\n",
    "# Datasets\n",
    "training_set = GSCDataset(\n",
    "    train=True, \n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "    ]), \n",
    ")\n",
    "testing_set = GSCDataset(\n",
    "    train=False, \n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "    ]),\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(dataset=training_set, batch_size=batch, shuffle=True, num_workers=8)\n",
    "test_loader  = DataLoader(dataset=testing_set , batch_size=batch, shuffle=True, num_workers=8)\n",
    "\n",
    "stats = slayer.utils.LearningStats()\n",
    "assistant = slayer.utils.Assistant(\n",
    "        net=net,\n",
    "        error=lambda output, target: F.mse_loss(output.flatten(), target.flatten()),\n",
    "        optimizer=optimizer,\n",
    "        stats=stats,\n",
    "        count_log=True,\n",
    "        lam=lam\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0d4e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "x_train = np.load(os.path.expanduser(\"/homes/ts468/data/rawSC/rawSC_80input/\") + \"training_x_data.npy\")\n",
    "y_train = np.load(os.path.expanduser(\"/homes/ts468/data/rawSC/rawSC_80input/\") + \"training_y_data.npy\")\n",
    "\n",
    "x_test = np.load(os.path.expanduser(\"/homes/ts468/data/rawSC/rawSC_80input/\") + \"testing_x_data.npy\")\n",
    "y_test = np.load(os.path.expanduser(\"/homes/ts468/data/rawSC/rawSC_80input/\") + \"testing_y_data.npy\")\n",
    "\n",
    "training_images = x_train #np.swapaxes(x_train, 1, 2) \n",
    "testing_images = x_test #np.swapaxes(x_test, 1, 2) \n",
    "\n",
    "training_images = training_images + abs(np.floor(training_images.min()))\n",
    "testing_images = testing_images + abs(np.floor(testing_images.min()))\n",
    "\n",
    "training_labels = y_train\n",
    "testing_labels = y_test\n",
    "\n",
    "# adding validation data if exists\n",
    "validation_images = np.array([])\n",
    "validation_labels = np.array([])\n",
    "if os.path.isfile(os.path.expanduser(\"/homes/ts468/data/rawSC/rawSC_80input/\") + \"validation_y_data.npy\"):\n",
    "        print(\"!! validation dataset loaded successfully\")\n",
    "        x_validation = np.load(os.path.expanduser(\"/homes/ts468/data/rawSC/rawSC_80input/\") + \"validation_x_data.npy\")\n",
    "        y_validation = np.load(os.path.expanduser(\"/homes/ts468/data/rawSC/rawSC_80input/\") + \"validation_y_data.npy\")\n",
    "\n",
    "        validation_images = x_validation #np.swapaxes(x_validation, 1, 2) \n",
    "        validation_images = validation_images + abs(np.floor(validation_images.min()))\n",
    "\n",
    "        validation_labels = y_validation\n",
    "\n",
    "training_images = np.expand_dims(training_images, 1)\n",
    "testing_images = np.expand_dims(testing_images, 1)\n",
    "validation_images = np.expand_dims(validation_images, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3facf6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=training_set, batch_size=batch, shuffle=True, num_workers=8)\n",
    "test_loader  = DataLoader(dataset=testing_set , batch_size=batch, shuffle=True, num_workers=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fifty-comfort",
   "metadata": {},
   "source": [
    "# Training loop\n",
    "\n",
    "Training loop mainly consists of looping over epochs and calling `assistant.train` and `assistant.test` utilities over training and testing dataset. The `assistant` utility takes care of statndard backpropagation procedure internally.\n",
    "\n",
    "* `stats` can be used in print statement to get formatted stats printout.\n",
    "* `stats.testing.best_loss` can be used to find out if the current iteration has the best testing loss. Here, we use it to save the best model.\n",
    "* `stats.update()` updates the stats collected for the epoch.\n",
    "* `stats.save` saves the stats in files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "antique-combining",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    if epoch in steps:\n",
    "        for param_group in optimizer.param_groups:    \n",
    "            print('\\nLearning rate reduction from', param_group['lr'])\n",
    "            param_group['lr'] /= 10/3\n",
    "        \n",
    "    for i, (input, ground_truth) in enumerate(train_loader): # training loop\n",
    "        assistant.train(input, ground_truth)\n",
    "        print(f'\\r[Epoch {epoch:3d}/{epochs}] {stats}', end='')\n",
    "    \n",
    "    for i, (input, ground_truth) in enumerate(test_loader): # testing loop\n",
    "        assistant.test(input, ground_truth)\n",
    "        print(f'\\r[Epoch {epoch:3d}/{epochs}] {stats}', end='')\n",
    "        \n",
    "    if epoch%50==49: print() \n",
    "    if stats.testing.best_loss:  \n",
    "        torch.save(net.state_dict(), trained_folder + '/network.pt')\n",
    "    stats.update()\n",
    "    stats.save(trained_folder + '/')\n",
    "    \n",
    "    # gradient flow monitoring\n",
    "    net.grad_flow(trained_folder + '/')\n",
    "    \n",
    "    # checkpoint saves\n",
    "    if epoch%10 == 0:\n",
    "        torch.save({'net': net.state_dict(), 'optimizer': optimizer.state_dict()}, logs_folder + f'/checkpoint{epoch}.pt')                   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "favorite-float",
   "metadata": {},
   "source": [
    "# Learning plots.\n",
    "\n",
    "Plotting the learning curves is as easy as calling `stats.plot()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "boolean-command",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.plot(figsize=(15, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fleet-monday",
   "metadata": {},
   "source": [
    "# Export the best trained model\n",
    "\n",
    "Load the best model during training and export it as hdf5 network. It is supported by `lava.lib.dl.netx` to automatically load the network as a lava process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "maritime-manchester",
   "metadata": {},
   "outputs": [],
   "source": [
    "net.load_state_dict(torch.load(trained_folder + '/network.pt'))\n",
    "net.export_hdf5(trained_folder + '/network.net')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reserved-quilt",
   "metadata": {},
   "source": [
    "# Operation count of trained model\n",
    "\n",
    "Here, we compare the synaptic operation and neuron activity of the trained SDNN and an ANN of iso-architecture."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quarterly-technical",
   "metadata": {},
   "source": [
    "## Event statistics on testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "southeast-character",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = []\n",
    "for i, (input, ground_truth) in enumerate(test_loader):\n",
    "    _, count = assistant.test(input, ground_truth)\n",
    "    count = (count.flatten()/(input.shape[-1]-1)/input.shape[0]).tolist() # count skips first events\n",
    "    counts.append(count) \n",
    "    print('\\rEvent count : ' + ', '.join([f'{c:.4f}' for c in count]), f'| {stats.testing}', end='') \n",
    "        \n",
    "counts = np.mean(counts, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "frequent-sight",
   "metadata": {},
   "source": [
    "# Event and Synops comparion with ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reasonable-volleyball",
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.compare_ops(net, counts, mse=stats.testing.min_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "263de8c3-c338-45e6-b30a-32dec35c2cc9",
   "metadata": {},
   "source": [
    "### How to learn more?\n",
    "\n",
    "If you want to learn more about Sigma-Delta neurons, take a look at the [Lava tutorial](https://github.com/lava-nc/lava/blob/main/tutorials/in_depth/tutorial10_sigma_delta_neurons.ipynb).\n",
    "\n",
    "Find out more about Lava and have a look at the [Lava documentation](https://lava-nc.org/ \"Lava Documentation\") or dive into the [source code](https://github.com/lava-nc/lava/ \"Lava Source Code\").\n",
    "\n",
    "To receive regular updates on the latest developments and releases of the Lava Software Framework please subscribe to the [INRC newsletter](http://eepurl.com/hJCyhb \"INRC Newsletter\")."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
